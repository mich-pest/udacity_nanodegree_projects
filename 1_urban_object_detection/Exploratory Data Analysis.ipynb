{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the dataset\n",
    "\n",
    "\n",
    "In this notebook, we will perform an EDA (Exploratory Data Analysis) on the processed Waymo dataset (data in the `processed` folder). In the first part, you will create a function to display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataset\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "label_map.pbtxt; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/michele/Documenti/Ud/nd013-c1-vision-starter/data/processed/*.tfrecord\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documenti/Ud/Urban_Object_Detection/utils.py:24\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(tfrecord_path, label_map)\u001b[0m\n\u001b[1;32m     21\u001b[0m input_config\u001b[38;5;241m.\u001b[39mlabel_map_path \u001b[38;5;241m=\u001b[39m label_map\n\u001b[1;32m     22\u001b[0m input_config\u001b[38;5;241m.\u001b[39mtf_record_input_reader\u001b[38;5;241m.\u001b[39minput_path[:] \u001b[38;5;241m=\u001b[39m [tfrecord_path]\n\u001b[0;32m---> 24\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:209\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(input_reader_config, batch_size, transform_input_data_fn, input_context, reduce_to_frame_fn)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_reader_config, input_reader_pb2\u001b[38;5;241m.\u001b[39mInputReader):\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_reader_config not of type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    207\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_reader_pb2.InputReader.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 209\u001b[0m decoder \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_reader_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_reader_config\u001b[38;5;241m.\u001b[39mWhichOneof(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_reader\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_record_input_reader\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    212\u001b[0m   config \u001b[38;5;241m=\u001b[39m input_reader_config\u001b[38;5;241m.\u001b[39mtf_record_input_reader\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/object_detection/builders/decoder_builder.py:51\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(input_reader_config)\u001b[0m\n\u001b[1;32m     49\u001b[0m input_type \u001b[38;5;241m=\u001b[39m input_reader_config\u001b[38;5;241m.\u001b[39minput_type\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_type \u001b[38;5;241m==\u001b[39m input_reader_pb2\u001b[38;5;241m.\u001b[39mInputType\u001b[38;5;241m.\u001b[39mValue(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_EXAMPLE\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 51\u001b[0m   decoder \u001b[38;5;241m=\u001b[39m \u001b[43mtf_example_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTfExampleDecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m      \u001b[49m\u001b[43mload_instance_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_reader_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_instance_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m      \u001b[49m\u001b[43mload_multiclass_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_reader_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_multiclass_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m      \u001b[49m\u001b[43mload_context_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_reader_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_context_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m      \u001b[49m\u001b[43minstance_mask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_reader_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlabel_map_proto_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_map_proto_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_display_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_reader_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_display_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_additional_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_reader_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_additional_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_keypoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_reader_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_keypoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m      \u001b[49m\u001b[43mexpand_hierarchy_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_reader_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_labels_hierarchy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m      \u001b[49m\u001b[43mload_dense_pose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_reader_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dense_pose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m      \u001b[49m\u001b[43mload_track_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_reader_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_track_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m      \u001b[49m\u001b[43mload_keypoint_depth_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_reader_config\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_keypoint_depth_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m decoder\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_type \u001b[38;5;241m==\u001b[39m input_reader_pb2\u001b[38;5;241m.\u001b[39mInputType\u001b[38;5;241m.\u001b[39mValue(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_SEQUENCE_EXAMPLE\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/object_detection/data_decoders/tf_example_decoder.py:458\u001b[0m, in \u001b[0;36mTfExampleDecoder.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    450\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems_to_handlers[\n\u001b[1;32m    451\u001b[0m       fields\u001b[38;5;241m.\u001b[39mInputDataFields\u001b[38;5;241m.\u001b[39mgroundtruth_track_ids] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    452\u001b[0m           slim_example_decoder\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage/object/track/label\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_map_proto_file:\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;66;03m# If the label_map_proto is provided, try to use it in conjunction with\u001b[39;00m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;66;03m# the class text, and fall back to a materialized ID.\u001b[39;00m\n\u001b[1;32m    457\u001b[0m   label_handler \u001b[38;5;241m=\u001b[39m slim_example_decoder\u001b[38;5;241m.\u001b[39mBackupHandler(\n\u001b[0;32m--> 458\u001b[0m       \u001b[43m_ClassTensorHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage/object/class/text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_map_proto_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    461\u001b[0m       slim_example_decoder\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage/object/class/label\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    462\u001b[0m   image_label_handler \u001b[38;5;241m=\u001b[39m slim_example_decoder\u001b[38;5;241m.\u001b[39mBackupHandler(\n\u001b[1;32m    463\u001b[0m       _ClassTensorHandler(\n\u001b[1;32m    464\u001b[0m           fields\u001b[38;5;241m.\u001b[39mTfExampleFields\u001b[38;5;241m.\u001b[39mimage_class_text,\n\u001b[1;32m    465\u001b[0m           label_map_proto_file,\n\u001b[1;32m    466\u001b[0m           default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    467\u001b[0m       slim_example_decoder\u001b[38;5;241m.\u001b[39mTensor(fields\u001b[38;5;241m.\u001b[39mTfExampleFields\u001b[38;5;241m.\u001b[39mimage_class_label))\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/object_detection/data_decoders/tf_example_decoder.py:92\u001b[0m, in \u001b[0;36m_ClassTensorHandler.__init__\u001b[0;34m(self, tensor_key, label_map_proto_file, shape_keys, shape, default_value)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     68\u001b[0m              tensor_key,\n\u001b[1;32m     69\u001b[0m              label_map_proto_file,\n\u001b[1;32m     70\u001b[0m              shape_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m              shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m              default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     73\u001b[0m   \u001b[38;5;124;03m\"\"\"Initializes the LookupTensor handler.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m  Simply calls a vocabulary (most often, a label mapping) lookup.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    ValueError: if both `shape_keys` and `shape` are specified.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m   name_to_id \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_map_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_label_map_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlabel_map_proto_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_display_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m   \u001b[38;5;66;03m# We use a default_value of -1, but we expect all labels to be contained\u001b[39;00m\n\u001b[1;32m     95\u001b[0m   \u001b[38;5;66;03m# in the label map.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# Dynamically try to load the tf v2 lookup, falling back to contrib\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/object_detection/utils/label_map_util.py:201\u001b[0m, in \u001b[0;36mget_label_map_dict\u001b[0;34m(label_map_path_or_proto, use_display_name, fill_in_gaps_and_background)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m\"\"\"Reads a label map and returns a dictionary of label names to id.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m  negative values.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(label_map_path_or_proto, string_types):\n\u001b[0;32m--> 201\u001b[0m   label_map \u001b[38;5;241m=\u001b[39m \u001b[43mload_labelmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_map_path_or_proto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m   _validate_label_map(label_map_path_or_proto)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/object_detection/utils/label_map_util.py:168\u001b[0m, in \u001b[0;36mload_labelmap\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"Loads label map proto.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m  a StringIntLabelMapProto\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mGFile(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m--> 168\u001b[0m   label_map_string \u001b[38;5;241m=\u001b[39m \u001b[43mfid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m   label_map \u001b[38;5;241m=\u001b[39m string_int_label_map_pb2\u001b[38;5;241m.\u001b[39mStringIntLabelMap()\n\u001b[1;32m    170\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/lib/io/file_io.py:114\u001b[0m, in \u001b[0;36mFileIO.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    103\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns the contents of a file as a string.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m  Starts reading from current position in file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    string if in string (regular) mode.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preread_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    116\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/lib/io/file_io.py:76\u001b[0m, in \u001b[0;36mFileIO._preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_check_passed:\n\u001b[1;32m     74\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mPermissionDeniedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt open for reading\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_buf \u001b[38;5;241m=\u001b[39m \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBufferedInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: label_map.pbtxt; No such file or directory"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(\"/nd013-c1-vision-starter/data/processed/*.tfrecord\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function to display an image and the bounding boxes\n",
    "\n",
    "Implement the `display_instances` function below. This function takes a batch as an input and display an image with its corresponding bounding boxes. The only requirement is that the classes should be color coded (eg, vehicles in red, pedestrians in blue, cyclist in green)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_instances(batch):\n",
    "    \"\"\"\n",
    "    This function takes a batch from the dataset and display the image with \n",
    "    the associated bounding boxes.\n",
    "    \"\"\"\n",
    "    print(\"Dataset 10 images sample\")\n",
    "    class_colormap = {1: 'r', 2: 'g', 4: 'b'}\n",
    "    for item in batch:\n",
    "        plt.figure()\n",
    "        image = item['image'].numpy()\n",
    "        bboxes = item['groundtruth_boxes'].numpy()\n",
    "        classes = item['groundtruth_classes'].numpy()\n",
    "        bboxes = bboxes * 640\n",
    "        img = Image.fromarray(image, 'RGB')\n",
    "        plt.imshow(img)\n",
    "        for cl, box in zip(classes, bboxes):\n",
    "            y1, x1, y2, x2 = box\n",
    "            ax = plt.gca()\n",
    "            ax.add_patch(patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, edgecolor=class_colormap[cl], facecolor='none'))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display 10 images \n",
    "\n",
    "Using the dataset created in the second cell and the function you just coded, display 10 random images with the associated bounding boxes. You can use the methods `take` and `shuffle` on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(1000)\n",
    "display_images(dataset.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional EDA\n",
    "\n",
    "In this last part, you are free to perform any additional analysis of the dataset. What else would like to know about the data?\n",
    "For example, think about data distribution. So far, you have only looked at a single file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_counter = np.zeros(3)\n",
    "\n",
    "def plot_distrib(dataset):\n",
    "    print(\"Collecting data...\")\n",
    "    for item in dataset:\n",
    "        classes = item['groundtruth_classes'].numpy()\n",
    "        for cl in classes:\n",
    "            if cl == 4: cl -= 1\n",
    "            cl_counter[cl-1] += 1\n",
    "            \n",
    "    print(\"Displaying distribution...\")\n",
    "    plt.bar([1, 2, 4], cl_counter, width=0.8, color=['r','g','b'])\n",
    "    plt.xlabel('Classes ids')   \n",
    "    plt.ylabel('Occurrences')\n",
    "    plt.title('Class distribution')\n",
    "    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with a subset of the real dataset (limited power)\n",
    "plot_distrib(dataset.take(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
